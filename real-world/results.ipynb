{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\"EDC\", \"AMAXSC\", \"M4GP\", \"lda\",  \"decision_tree\", \"MLP\", \"random_forest\", \"svm_rbf\"]\n",
    "score_metric = \"auc_score\"\n",
    "score_metric_index = 0 if score_metric == \"auc_score\" else 1\n",
    "\n",
    "result_files = os.listdir(\"results\")\n",
    "results = []\n",
    "for result_file in result_files:\n",
    "    dataset, search_strategy, optimiser, random_seed = result_file.split(\n",
    "        \".\"\n",
    "    )[0].split(\"-\")\n",
    "    with open(f\"results/{result_file}\", \"rb\") as f:\n",
    "        res = pickle.load(f)\n",
    "    for elapsed_time, auc_score, accuracy_score in zip(res[\"elapsed_time\"], res[\"auc_score\"], res[\"accuracy_score\"]):\n",
    "        results.append(\n",
    "            [\n",
    "                dataset,\n",
    "                \"EDC\",  # \"classifier\n",
    "                search_strategy,\n",
    "                optimiser,\n",
    "                elapsed_time,\n",
    "                auc_score,\n",
    "                accuracy_score,\n",
    "                random_seed,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "result_files = os.listdir(\"comparison_results\")\n",
    "for result_file in result_files:\n",
    "    dataset, classifier, random_seed = result_file.split(\n",
    "        \".\"\n",
    "    )[0].split(\"-\")\n",
    "    with open(f\"comparison_results/{result_file}\", \"rb\") as f:\n",
    "        res = pickle.load(f)\n",
    "    for elapsed_time, auc_score, accuracy_score in zip(res[\"elapsed_time\"], res[\"auc_score\"], res[\"accuracy_score\"]):\n",
    "        results.append(\n",
    "            [\n",
    "                dataset,\n",
    "                classifier,  # \"classifier\n",
    "                None,\n",
    "                None,\n",
    "                elapsed_time,\n",
    "                auc_score,\n",
    "                accuracy_score,\n",
    "                random_seed,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"dataset\",\n",
    "        \"classifier\",\n",
    "        \"search_strategy\",\n",
    "        \"optimiser\",\n",
    "        \"elapsed_time\",\n",
    "        \"auc_score\",\n",
    "        \"accuracy_score\",\n",
    "        \"random_seed\"\n",
    "    ],\n",
    "    data=results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dataset classifier search_strategy     optimiser  elapsed_time  \\\n",
      "0     BANKNOTE        EDC            beam  hill_climber      1.718301   \n",
      "1     BANKNOTE        EDC            beam  hill_climber      1.867863   \n",
      "2     BANKNOTE        EDC            beam  hill_climber      1.700837   \n",
      "3     BANKNOTE        EDC            beam  hill_climber      1.801598   \n",
      "4    HEPATITIS        EDC            beam  hill_climber     36.987851   \n",
      "..         ...        ...             ...           ...           ...   \n",
      "845  OCCUPANCY       M4GP            None          None  10925.042849   \n",
      "846  OCCUPANCY       M4GP            None          None   7885.030924   \n",
      "847  OCCUPANCY       M4GP            None          None   8350.017893   \n",
      "848  OCCUPANCY       M4GP            None          None   9791.152997   \n",
      "849      ADULT       M4GP            None          None  68018.334314   \n",
      "\n",
      "     auc_score  accuracy_score random_seed  \n",
      "0     1.000000        1.000000   1805819_2  \n",
      "1     1.000000        1.000000   1805819_0  \n",
      "2     1.000000        1.000000   1805819_1  \n",
      "3     0.999571        0.978102   1805819_3  \n",
      "4     1.000000        0.875000   1805819_9  \n",
      "..         ...             ...         ...  \n",
      "845   0.994187        0.992218   475236722  \n",
      "846   0.992767        0.988813   475236722  \n",
      "847   0.988118        0.983949   475236722  \n",
      "848   0.988099        0.988813   475236722  \n",
      "849   0.789898        0.820676  3504620456  \n",
      "\n",
      "[850 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADULT&0.8800 ($\\pm0.01$)&0.8010 ($\\pm0.00$)&0.7899 ($\\pmnan$)&0.9018 ($\\pm0.00$)&0.7308 ($\\pm0.01$)&0.9018 ($\\pm0.00$)&0.8799 ($\\pm0.01$)&0.8983 ($\\pm0.00$)\\\\\n",
      "BANKNOTE&1.0000 ($\\pm0.00$)&0.9925 ($\\pm0.00$)&1.0000 ($\\pm0.00$)&0.9997 ($\\pm0.00$)&0.9840 ($\\pm0.01$)&1.0000 ($\\pm0.00$)&1.0000 ($\\pm0.00$)&1.0000 ($\\pm0.00$)\\\\\n",
      "BREAST&0.5945 ($\\pm0.18$)&0.5728 ($\\pm0.08$)&0.6079 ($\\pm0.10$)&0.6500 ($\\pm0.12$)&0.5782 ($\\pm0.07$)&0.7116 ($\\pm0.12$)&0.6558 ($\\pm0.07$)&0.7257 ($\\pm0.12$)\\\\\n",
      "CREDIT&0.9137 ($\\pm0.02$)&0.8935 ($\\pm0.05$)&0.8421 ($\\pm0.04$)&0.9299 ($\\pm0.03$)&0.8197 ($\\pm0.04$)&0.9126 ($\\pm0.03$)&0.9313 ($\\pm0.03$)&0.9204 ($\\pm0.03$)\\\\\n",
      "CYLINDER&0.7309 ($\\pm0.09$)&0.5998 ($\\pm0.09$)&0.6387 ($\\pm0.13$)&0.7628 ($\\pm0.09$)&0.6516 ($\\pm0.11$)&0.8201 ($\\pm0.06$)&0.8659 ($\\pm0.08$)&0.7737 ($\\pm0.08$)\\\\\n",
      "DIABETES&0.8280 ($\\pm0.05$)&0.8055 ($\\pm0.06$)&0.7181 ($\\pm0.03$)&0.8321 ($\\pm0.06$)&0.6614 ($\\pm0.07$)&0.8360 ($\\pm0.03$)&0.8246 ($\\pm0.07$)&0.8452 ($\\pm0.04$)\\\\\n",
      "HEPATITIS&0.8359 ($\\pm0.13$)&0.8345 ($\\pm0.16$)&0.7005 ($\\pm0.29$)&0.7876 ($\\pm0.20$)&0.7701 ($\\pm0.20$)&0.8583 ($\\pm0.20$)&0.9180 ($\\pm0.09$)&0.8167 ($\\pm0.28$)\\\\\n",
      "IONOSPHERE&0.8708 ($\\pm0.10$)&0.8394 ($\\pm0.08$)&0.8573 ($\\pm0.06$)&0.9217 ($\\pm0.07$)&0.8779 ($\\pm0.09$)&0.9736 ($\\pm0.03$)&0.9759 ($\\pm0.03$)&0.9791 ($\\pm0.02$)\\\\\n",
      "OCCUPANCY&0.9960 ($\\pm0.00$)&0.9882 ($\\pm0.01$)&0.9906 ($\\pm0.00$)&0.9942 ($\\pm0.00$)&0.9875 ($\\pm0.00$)&0.9974 ($\\pm0.00$)&0.9991 ($\\pm0.00$)&0.9929 ($\\pm0.00$)\\\\\n",
      "SONAR&0.8019 ($\\pm0.08$)&0.7252 ($\\pm0.14$)&0.7308 ($\\pm0.18$)&0.7789 ($\\pm0.09$)&0.7218 ($\\pm0.11$)&0.9402 ($\\pm0.05$)&0.9519 ($\\pm0.03$)&0.9301 ($\\pm0.08$)\\\\\n",
      "WISCONSIN&0.5859 ($\\pm0.11$)&0.5964 ($\\pm0.13$)&0.5670 ($\\pm0.12$)&0.5863 ($\\pm0.10$)&0.4881 ($\\pm0.13$)&0.5781 ($\\pm0.11$)&0.6132 ($\\pm0.08$)&0.6224 ($\\pm0.10$)\\\\\n",
      "\\midrule\n",
      "Average Score&0.8216&0.7863&0.7675&0.8314&0.7519&0.8663&0.8741&0.8640\\\\\n",
      "Average Rank&4.45&6.36&6.18&3.91&7.36&2.64&2.36&2.45\\\\\n"
     ]
    }
   ],
   "source": [
    "dataset_grouped = df.groupby([\"dataset\"])\n",
    "all_scores = []\n",
    "all_stds = []\n",
    "for dataset_group in dataset_grouped:\n",
    "    scores = {}\n",
    "    stds = {}\n",
    "    dataset = dataset_group[0][0]\n",
    "    if dataset == \"BANANA\" or (dataset.startswith(\"AD0\")):\n",
    "        continue\n",
    "    for classifier_group in dataset_group[1].groupby([\"classifier\"]):\n",
    "        number_of_folds_done = len(classifier_group[1])\n",
    "\n",
    "        classifier = classifier_group[0][0]\n",
    "        mean_auc = classifier_group[1][\"auc_score\"].mean()\n",
    "        std_auc = classifier_group[1][\"auc_score\"].std()\n",
    "        mean_acc = classifier_group[1][\"accuracy_score\"].mean()\n",
    "        std_acc = classifier_group[1][\"accuracy_score\"].std()\n",
    "        scores[classifier] = (mean_auc, mean_acc)\n",
    "        stds[classifier] = (std_auc, std_acc)\n",
    "        \n",
    "\n",
    "\n",
    "    # Get the ranks\n",
    "    for classifier in classifiers:\n",
    "        if classifier not in scores:\n",
    "            scores[classifier] = (0, 0)\n",
    "            stds[classifier] = (0, 0)\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        current_score = scores[classifier][score_metric_index]\n",
    "        rank = 1\n",
    "        for other_classifier in classifiers:\n",
    "            if other_classifier == classifier:\n",
    "                continue\n",
    "            if scores[other_classifier][score_metric_index] > current_score:\n",
    "                rank += 1\n",
    "        scores[classifier] = (scores[classifier][0], scores[classifier][1], rank)\n",
    "    \n",
    "\n",
    "    print(f\"{dataset}\", end=\"&\")\n",
    "    if score_metric == \"auc_score\":\n",
    "        # Print AUC scores\n",
    "        for clf in classifiers:\n",
    "            print(f\"{scores[clf][0]:.4f} ($\\\\pm{stds[clf][0]:.2f}$)\", end=\"&\")\n",
    "\n",
    "    if score_metric == \"accuracy_score\":\n",
    "        # Print Acc\n",
    "        for clf in classifiers:\n",
    "            print(f\"{scores[clf][1]:.4f} ($\\\\pm{stds[clf][1]:.2f}$)\", end=\"&\")\n",
    "    \n",
    "    # # Print rank\n",
    "    # for clf in classifiers:\n",
    "    #     print(f\"{scores[clf][2]}\", end=\"&\")\n",
    "    \n",
    "    print(f\"\\b\\\\\\\\\")\n",
    "\n",
    "    all_scores.append(scores)\n",
    "    all_stds.append(stds)\n",
    "    # print(f\"{dataset} & {scores['EDC'][0]:.4f} & {scores['random_forest'][0]:.4f} & {scores['EDC'][1]:.4f} & {scores['random_forest'][1]:.4f} \\\\\\\\\")\n",
    "\n",
    "\n",
    "\n",
    "# Get average ranks\n",
    "average_ranks = {}\n",
    "average_aucs = {}\n",
    "average_accs = {}\n",
    "for classifier in classifiers:\n",
    "    average_ranks[classifier] = 0\n",
    "    average_aucs[classifier] = 0\n",
    "    average_accs[classifier] = 0\n",
    "    for dataset in all_scores:\n",
    "        if classifier not in dataset:\n",
    "            continue\n",
    "        average_ranks[classifier] += dataset[classifier][2]\n",
    "        average_aucs[classifier] += dataset[classifier][0]\n",
    "        average_accs[classifier] += dataset[classifier][1]\n",
    "    average_ranks[classifier] /= len(all_scores)\n",
    "    average_aucs[classifier] /= len(all_scores)\n",
    "    average_accs[classifier] /= len(all_scores)\n",
    "\n",
    "print(\"\\\\midrule\")\n",
    "print(f\"Average Score&\", end=\"\")\n",
    "for classifier in classifiers:\n",
    "    print(f\"{average_aucs[classifier]:.4f}\", end=\"&\")\n",
    "print(f\"\\b\\\\\\\\\")\n",
    "\n",
    "print(f\"Average Rank&\", end=\"\")\n",
    "for classifier in classifiers:\n",
    "    print(f\"{average_ranks[classifier]:.2f}\", end=\"&\")\n",
    "print(f\"\\b\\\\\\\\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
